# Paths are mounted into the DGX containers. Replace REPLACE_WITH_SNAPSHOT accordingly.
# MODELS_DIR defaults to the HuggingFace cache, but can be overridden for DGX mounts.
MODELS_DIR=${HOME}/.cache/huggingface/hub

# Embeddings (service: embeddings-gpu)
EMBEDDINGS_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-Embedding-4B-GGUF/snapshots/REPLACE_WITH_SNAPSHOT/Qwen3-Embedding-4B-Q8_0.gguf

# LLM Instruct (service: llm-instruct) - used for research/planning/search/knowledge_preparation
LLM_INSTRUCT_MODEL_PATH=/mnt/models/models--ggml-org--gpt-oss-20b-GGUF/snapshots/REPLACE_WITH_SNAPSHOT/gpt-oss-20b-mxfp4.gguf

# LLM Reasoning (service: llm-reasoning) - used for writer
LLM_REASONING_MODEL_PATH=/mnt/models/models--mistralai--Ministral-3-14B-Reasoning-2512-GGUF/snapshots/REPLACE_WITH_SNAPSHOT/Ministral-3-14B-Reasoning-2512-Q8_0.gguf

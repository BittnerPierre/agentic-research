x-llama-build: &llama-build
  build:
    context: .
    dockerfile: docker/Dockerfile.llamacpp
  image: local/llama.cpp:server-cuda

services:
  embeddings-gpu:
    <<: *llama-build
    volumes:
      - ${MODELS_DIR:-${HOME}/.cache/huggingface}:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command:
      - "-hf"
      - "${EMBEDDINGS_MODEL_REPO:-Qwen/Qwen3-Embedding-4B-GGUF}"
      - "--port"
      - "${EMBEDDINGS_PORT:-8003}"
      - "--host"
      - "0.0.0.0"
      - "--jinja"
      - "--embeddings"
    ports:
      - "${EMBEDDINGS_PORT:-8003}:${EMBEDDINGS_PORT:-8003}"
    profiles:
      - v1-dgx

  llm-instruct:
    <<: *llama-build
    volumes:
      - ${MODELS_DIR:-${HOME}/.cache/huggingface}:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command:
      - "-hf"
      - "${LLM_INSTRUCT_MODEL_REPO:-ggml-org/gpt-oss-20b-GGUF}"
      - "--port"
      - "${LLM_INSTRUCT_PORT:-8002}"
      - "--host"
      - "0.0.0.0"
      - "-n"
      - "${LLM_INSTRUCT_N_CTX:-2048}"
      - "--n-gpu-layers"
      - "${LLM_INSTRUCT_N_GPU_LAYERS:-999}"
      - "--jinja"
    ports:
      - "${LLM_INSTRUCT_PORT:-8002}:${LLM_INSTRUCT_PORT:-8002}"
    profiles:
      - v1-dgx

  llm-reasoning:
    <<: *llama-build
    volumes:
      - ${MODELS_DIR:-${HOME}/.cache/huggingface}:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command:
      - "-hf"
      - "${LLM_REASONING_MODEL_REPO:-mistralai/Ministral-3-14B-Reasoning-2512}"
      - "--port"
      - "${LLM_REASONING_PORT:-8004}"
      - "--host"
      - "0.0.0.0"
      - "-n"
      - "${LLM_REASONING_N_CTX:-2048}"
      - "--n-gpu-layers"
      - "${LLM_REASONING_N_GPU_LAYERS:-999}"
      - "--jinja"
    ports:
      - "${LLM_REASONING_PORT:-8004}:${LLM_REASONING_PORT:-8004}"
    profiles:
      - v1-dgx

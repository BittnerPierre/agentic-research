##
## GLM
##

MODELS_DIR=${HOME}/.cache/huggingface/hub

LLM_INSTRUCT_MODEL_PATH=/mnt/models/models--bartowski--zai-org_GLM-4.7-Flash-GGUF/snapshots/464d07505b441959737cd04d900f047469614c8d/zai-org_GLM-4.7-Flash-Q5_K_M.gguf

LLM_INSTRUCT_EXTRA_PARAMS="--parallel 1 --flash-attn on"
# LLM_INSTRUCT_CTX_SIZE=65536
LLM_INSTRUCT_CTX_SIZE=32768
# LLM_INSTRUCT_CTX_SIZE=0
# LLM_INSTRUCT_N_PREDICT=8192
LLM_INSTRUCT_BATCH_SIZE=256 # 512
LLM_INSTRUCT_UBATCH_SIZE=256 # 512
# LLM_INSTRUCT_N_GPU_LAYERS=70

LLM_REASONING_MODEL_PATH=/mnt/models/models--bartowski--THUDM_GLM-Z1-32B-0414-GGUF/snapshots/90b92cf34fcc79d39a73cc394d9c78d3c0280c7d/THUDM_GLM-Z1-32B-0414-Q5_K_M.gguf

LLM_REASONING_EXTRA_PARAMS="--parallel 1 --flash-attn on"
LLM_REASONING_CTX_SIZE=12288 #32768
# LLM_REASONING_CTX_SIZE=0
LLM_REASONING_N_PREDICT=2048 # 8192
LLM_REASONING_BATCH_SIZE=128 #512
LLM_REASONING_UBATCH_SIZE=128 #512
# LLM_REASONING_N_GPU_LAYERS=999

EMBEDDINGS_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-Embedding-4B-GGUF/snapshots/f4602530db1d980e16da9d7d3a70294cf5c190be/Qwen3-Embedding-4B-Q8_0.gguf

# FOR DOWNLOAD

LLM_INSTRUCT_MODEL_REPO=bartowski/zai-org_GLM-4.7-Flash-GGUF
INSTRUCT_GGUF_PATTERN=zai-org_GLM-4.7-Flash-Q5_K_M.gguf

LLM_REASONING_MODEL_REPO=bartowski/THUDM_GLM-Z1-32B-0414-GGUF
REASONING_GGUF_PATTERN=THUDM_GLM-Z1-32B-0414-Q5_K_M.gguf

EMBEDDINGS_MODEL_REPO=Qwen/Qwen3-Embedding-4B-GGUF
EMBEDDINGS_GGUF_PATTERN=Qwen3-Embedding-4B-Q8_0.gguf




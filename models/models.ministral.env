##
### MINISTRAL 3 14B
##

MODELS_DIR=${HOME}/.cache/huggingface/hub

LLM_INSTRUCT_MODEL_PATH=/mnt/models/models--mistralai--Ministral-3-14B-Instruct-2512-GGUF/snapshots/74fac473c43357d7fb2671713608183cc72496d0/Ministral-3-14B-Instruct-2512-Q4_K_M.gguf

LLM_INSTRUCT_EXTRA_PARAMS="--flash-attn on"
# LLM_INSTRUCT_CTX_SIZE=65536
LLM_INSTRUCT_CTX_SIZE=32768
# LLM_INSTRUCT_CTX_SIZE=0
# LLM_INSTRUCT_N_PREDICT=65536
# LLM_INSTRUCT_BATCH_SIZE=512
# LLM_INSTRUCT_UBATCH_SIZE=512
# LLM_INSTRUCT_N_GPU_LAYERS=70


LLM_REASONING_MODEL_PATH=/mnt/models/models--mistralai--Ministral-3-14B-Reasoning-2512-GGUF/snapshots/fe3b038f30334729263d860d5dadbaa34e0f2a18/Ministral-3-14B-Reasoning-2512-Q4_K_M.gguf

LLM_REASONING_EXTRA_PARAMS="--flash-attn on"
# LLM_REASONING_CTX_SIZE=32768
#LLM_REASONING_CTX_SIZE=0
# LLM_REASONING_N_PREDICT=8192
# LLM_REASONING_BATCH_SIZE=512
# LLM_REASONING_UBATCH_SIZE=512
# LLM_REASONING_N_GPU_LAYERS=999

EMBEDDINGS_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-Embedding-4B-GGUF/snapshots/f4602530db1d980e16da9d7d3a70294cf5c190be/Qwen3-Embedding-4B-Q8_0.gguf

# FOR DOWNLOAD

LLM_INSTRUCT_MODEL_REPO=mistralai/Ministral-3-14B-Instruct-2512-GGUF
INSTRUCT_GGUF_PATTERN=Ministral-3-14B-Instruct-2512-Q5_K_M.gguf

LLM_REASONING_MODEL_REPO=mistralai/Ministral-3-14B-Reasoning-2512
REASONING_GGUF_PATTERN=Ministral-3-14B-Reasoning-2512*.gguf

EMBEDDINGS_MODEL_REPO=Qwen/Qwen3-Embedding-4B-GGUF
EMBEDDINGS_GGUF_PATTERN=Qwen3-Embedding-4B-Q8_0.gguf




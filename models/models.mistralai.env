##
## MISTRAL AI (Small 3.2 + Magistral-Small)
##

MODELS_DIR=${HOME}/.cache/huggingface/hub

LLM_INSTRUCT_MODEL_PATH=/mnt/models/models--unsloth--Mistral-Small-3.2-24B-Instruct-2506-GGUF/snapshots/b750ec2299225e492f1bd27cab88a0a595fa848f/Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M.gguf
# LLM_INSTRUCT_CTX_SIZE=65536
LLM_INSTRUCT_CTX_SIZE=32768
# LLM_INSTRUCT_CTX_SIZE=0
# LLM_INSTRUCT_N_PREDICT=8192
# LLM_INSTRUCT_BATCH_SIZE=512
# LLM_INSTRUCT_UBATCH_SIZE=512
# LLM_INSTRUCT_N_GPU_LAYERS=-70
LLM_INSTRUCT_EXTRA_PARAMS="--temp 0.15 --top-k -1 --top-p 1.00 --flash-attn on"



LLM_REASONING_MODEL_PATH=/mnt/models/models--unsloth--Magistral-Small-2509-GGUF/snapshots/77fe877ee8e44eadf97235a1ad77471678eed310/Magistral-Small-2509-Q4_K_M.gguf

LLM_REASONING_EXTRA_PARAMS="--temp 0.7 --top-k -1 --top-p 0.95 --flash-attn on"

# LLM_REASONING_CTX_SIZE=32768
# LLM_REASONING_N_PREDICT=8192
# LLM_REASONING_BATCH_SIZE=512
# LLM_REASONING_UBATCH_SIZE=512
# LLM_REASONING_N_GPU_LAYERS=999

EMBEDDINGS_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-Embedding-4B-GGUF/snapshots/f4602530db1d980e16da9d7d3a70294cf5c190be/Qwen3-Embedding-4B-Q8_0.gguf

# FOR DOWNLOAD

LLM_INSTRUCT_MODEL_REPO=unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF
INSTRUCT_GGUF_PATTERN=Mistral-Small-3.2-24B-Instruct-2506-Q5_K_M.gguf
#INSTRUCT_GGUF_PATTERN=Mistral-Small-3.2-24B-Instruct-2506-BF16.gguf

LLM_REASONING_MODEL_REPO=unsloth/Magistral-Small-2509-GGUF
# mistralai/Magistral-Small-2509-GGUF
REASONING_GGUF_PATTERN=Magistral-Small-2509-Q4_K_M.gguf

EMBEDDINGS_MODEL_REPO=Qwen/Qwen3-Embedding-4B-GGUF
EMBEDDINGS_GGUF_PATTERN=Qwen3-Embedding-4B-Q8_0.gguf




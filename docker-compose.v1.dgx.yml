services:
  embeddings-gpu:
    command: ["--model-id", "BAAI/bge-large-en-v1.5", "--port", "8003"]

  llama-cpp-gpu:
    command: ["sh", "-lc", "./server -m /models/model.gguf --host 0.0.0.0 --port 8002"]

services:
  embeddings-gpu:
    command: ["--model-id", "BAAI/bge-large-en-v1.5", "--port", "8003"]

  llama-cpp-gpu:
    command: ["--server", "-m", "/models/model.gguf", "--host", "0.0.0.0", "--port", "8002"]

La gestion de la mémoire dans les systèmes multi-agents d'IA repose sur des modèles distincts de mémoire à court terme et à long terme, essentiels pour la conservation et la récupération des informations nécessaires au fonctionnement des agents.

Les modèles de mémoire à court terme incluent la mémoire en contexte immédiat (ou mémoire de travail) que les modèles de langage utilisent pour traiter les tâches en cours, par exemple via le prompt engineering (ingénierie des invites). Cette mémoire est limitée en capacité et durée, généralement sur une seule session ou quelques instants, mais permet d'effectuer des raisonnements complexes et tâches décomposées efficacement.

La mémoire à long terme est externalisée et permet la conservation durable, souvent à l'aide de magasins vectoriels ou bases externes, facilitant la récupération rapide d'informations pertinentes même après de longues périodes. Cela inclut la capacité de contextualiser et d'actualiser les connaissances en fonction des nouvelles entrées ou interactions, garantissant ainsi que les agents disposent des données les plus pertinentes et à jour.

Parmi les techniques de stockage, on trouve l'utilisation de bases de données vectorielles optimisées pour la recherche de similarité rapide (MIPS : Maximum Inner Product Search), qui quantifient et indexent les données pour un accès et une correspondance efficaces. Des méthodes comme la compression intelligente du contexte permettent aussi de réduire la charge mémoire tout en conservant la cohérence des ensembles d'informations sur de longues interactions.

Pour la récupération, les systèmes utilisent des modèles de recherche pertinents basés sur la similarité sémantique, l'importance et la récence des informations. Ceci est souvent intégré dans des boucles d'interaction où les agents peuvent extraire, synthétiser et contextualiser les informations récupérées pour maintenir un dialogue ou une exécution de tâche cohérente et performante.

Enfin, dans un contexte multi-agent, des architectures orchestrées favorisent la distribution des tâches, où une mémoire partagée ou dédiée à chaque agent peut être synchronisée et mise à jour pour suivre l'état global du système. Cela inclut aussi des techniques d'auto-réflexion et de gestion d'erreur où les agents évaluent et adaptent leurs stratégies de mémoire pour optimiser leur performance sur le long terme.

Cette approche globale permet aux systèmes multi-agents d'IA de gérer efficacement des tâches complexes nécessitant une mémoire dynamique, une mise à jour continue des connaissances et une interaction fluide entre agents et outils externes.
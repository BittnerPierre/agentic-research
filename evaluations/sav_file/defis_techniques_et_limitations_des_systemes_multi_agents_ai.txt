Les systèmes multi-agents en intelligence artificielle (IA) présentent plusieurs défis techniques et limitations majeures, notamment en termes de cohérence, de contrôle, d'éthique, de sécurité et de scalabilité. Voici un résumé des principaux enjeux identifiés dans la recherche et l'ingénierie de ces systèmes :

1. Problèmes de cohérence et d'exécution :
- Les agents sont généralement stateful, conservant un état sur de longues périodes et à travers de multiples appels d'outils, ce qui rend la gestion des erreurs complexe. Une erreur mineure peut se propager et entraîner des comportements imprévisibles.
- Le débogage est difficile car les agents prennent des décisions dynamiques non déterministes même avec des prompts identiques, nécessitant de nouvelles méthodes d'observabilité et de traçabilité des interactions.
- L'exécution synchrone actuelle crée des goulets d'étranglement, empêchant une coordination fluide entre agents. Passer à une exécution asynchrone pose des défis supplémentaires de coordination des résultats, de cohérence d'état et de gestion des erreurs.

2. Défis liés au contrôle et à la planification :
- Planifier sur des horizons longs avec décomposition de tâches demeure un défi, notamment parce que les agents peinent à ajuster leurs plans en cas d'erreurs inattendues, contrairement aux humains qui apprennent de leurs erreurs.
- La maîtrise des flux de contrôle complexes (exécution parallèle, conditionnelle, boucles) est essentielle, mais difficile à mettre en œuvre et à traduire en commandes exécutables fiables.
- La réflexion et la correction d'erreurs intercalées sont cruciales pour améliorer les performances et la robustesse, mais elles nécessitent un design sophistiqué d'auto-évaluation et d'auto-réflexion.

3. Limites éthiques et de sécurité :
- La capacité des agents à interagir avec des systèmes externes via des outils pose des risques : des erreurs ou des comportements indésirables peuvent entraîner des actions nuisibles (ex : transactions bancaires non autorisées).
- La confiance dans les capacités des systèmes et la mise en place de mesures de sécurité solides sont indispensables pour prévenir les manipulations malveillantes.

4. Problèmes de scalabilité :
- Les contextes limités (longueur de contexte finie dans les modèles) restreignent la quantité d'informations historiques et complexes pouvant être traitées en continu.
- Le coût en tokens est significatif : les systèmes multi-agents consomment beaucoup plus de ressources que les interactions de chat simples, ce qui nécessite que les tâches soient assez précieuses pour justifier cet investissement.
- Certaines tâches avec fortes dépendances ou nécessitant un partage de contexte important ne conviennent pas encore aux architectures multi-agents.

En résumé, malgré ces défis techniques, éthiques et opérationnels, les systèmes multi-agents en IA offrent un avantage considérable pour traiter des tâches complexes en exploitant une intelligence collective distribuée. Leur déploiement fiable à grande échelle requiert cependant une ingénierie avancée, incluant la conception soignée des prompts, la surveillance rigoureuse, et des stratégies robustes de gestion des erreurs et de coordination entre agents.

Sources :
- How_we_built_our_multi.md
- LLM_Powered_Autonomous_Agents.md
- Agents.md


Les systèmes multi-agents AI sont largement utilisés dans des contextes industriels et de recherche pour gérer des problèmes complexes avec des agents autonomes et spécialisés. Anthropic, par exemple, a développé un système de recherche multi-agent utilisant plusieurs agents Claude travaillant en parallèle sur différentes parties d'une problématique. Un agent principal (LeadResearcher) planifie la stratégie et délègue à des sous-agents spécialisés qui explorent indépendamment des sources d'information, synthétisant les données pour fournir des réponses de haute qualité. Ce système est conçu pour des tâches ouvertes et dynamiques de recherche où une approche en parallèle permet une meilleure couverture et efficacité qu’un agent unique. Les sous-agents utilisent également des heuristiques pour bien choisir leurs outils et ajuster leurs efforts en fonction de la complexité des requêtes, avec des stratégies telles que commencer par une exploration large puis se concentrer progressivement sur des détails spécifiques. Cette architecture améliore notablement la rapidité et la qualité des recherches complexes tout en permettant une gestion fine des ressources et un contrôle via des modes de réflexion étendus et des parallélisations des appels aux outils externes.

Les défis industriels incluent la coordination entre agents, la gestion des erreurs sur des longues interactions, et la nécessité d’une ingénierie rigoureuse pour passer du prototype à un système fiable en production. Anthropic a mis en place des pratiques robustes, comme l’évaluation des états finaux plutôt que l’analyse tour par tour, la gestion de la mémoire externe pour conserver le contexte sur de longs échanges, et l’utilisation d’agents pour tester et améliorer eux-mêmes la description des outils afin de réduire les erreurs. La synchronisation des sous-agents reste un goulot d’étranglement, et des améliorations futures impliquent une exécution plus asynchrone pour augmenter la parallélisation et la réactivité. Ces systèmes multi-agents sont particulièrement efficaces pour des tâches qui nécessitent une forte parallélisation, la gestion de grandes quantités d’information dépassant les limites d’un seul agent, ou l’interfaçage avec des outils complexes.

Chez OpenAI et d’autres leaders technologiques, on retrouve des architectures similaires où les agents pilotés par des grands modèles de langage (LLMs) agissent comme des orchestrateurs ou planificateurs capables de décomposer une tâche complexe en sous-tâches parallèles, en utilisant différents outils et en appliquant des mécanismes de réflexion et correction d’erreurs (pattern ReAct). Par exemple, HuggingGPT utilise ChatGPT comme cerveau planificateur pour distribuer des tâches à divers modèles Experts sur la plateforme HuggingFace, puis synthétiser les résultats. Des approches comme AutoGPT démontrent le potentiel d’agents autonomes avec contrôle LLM pour réaliser des buts complexes sans supervision directe. Ces systèmes intègrent aussi des mécanismes pour gérer l’ordre d’exécution en séquençant ou parallélisant les actions, améliorer la robustesse via l’auto-réflexion, et optimiser la coordination entre agents. L’efficacité repose aussi sur l’usage judicieux d’outils spécifiques et sur des manières de gérer la mémoire, la planification adaptative et l’évaluation continue des plans et résultats.
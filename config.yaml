# Configuration pour agentic-research
config_name: "default (mixed models)"

vector_store:
  # OpenAI Vector Store ID - https://platform.openai.com/storage/vector_stores/
  name: "agent-engineer-basic-course"
  description: "Vector store for agentic research experiments"
  expires_after_days: 30

vector_search:
  provider: "local"
  index_name: "agentic-research"
  embedding_function: "default"
  top_k: 5
  score_threshold: null

vector_mcp:
  command: "uvx"
  args: ["chroma-mcp"]

# Configuration des données d'entrée
data:
  # Fichier contenant les URLs à traiter (une par ligne)
  urls_file: "urls.txt"
  # Base de connaissances locale (JSON)
  knowledge_db_path: "data/knowledge_db.json"
  # Dossier de stockage local des fichiers .md
  local_storage_dir: "data/"

# Configuration de debug
debug:
  # Active le mode debug (garde les fichiers temporaires, logs verbeux)
  enabled: false # Activé pour utiliser le stockage local
  # Dossier pour sauvegarder les fichiers en mode debug
  output_dir: "debug_output"
  # Sauvegarder les rapports finaux en markdown
  save_reports: true
  # Afficher l'aperçu du contenu dans les logs
  show_content_preview: true

# Configuration du logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Configuration MCP (Model Context Protocol)
mcp:
  server_host: "0.0.0.0"
  server_port: 8001
  # Timeout pour les appels d'outils MCP (en secondes)
  # Augmenté à 10s car upload_files_to_vectorstore peut prendre ~6.5s
  # Valeur par défaut dans le SDK: 5.0s
  client_timeout_seconds: 10.0

# Configuration Models
models:
  research_model: "openai/gpt-4.1-mini"
  planning_model: "openai/o4-mini"
  search_model: "openai/gpt-4.1-mini" # Used for vector search summaries
  writer_model: "openai/gpt-4.1-mini"
  knowledge_preparation_model: "openai/gpt-4.1-mini"

# Configuration du manager
manager:
  default_manager: "agentic_manager" # Options: agentic_manager, manager, ou chemin.vers.ClasseManager

agents:
  max_search_plan: "2-3"
  output_dir: "output/"

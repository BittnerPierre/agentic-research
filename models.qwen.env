##
## QWEN MODELS
##

MODELS_DIR=${HOME}/.cache/huggingface/hub

LLM_INSTRUCT_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-14B-GGUF/snapshots/530227a7d994db8eca5ab5ced2fb692b614357fd/Qwen3-14B-Q5_K_M.gguf

LLM_INSTRUCT_EXTRA_PARAMS="--flash-attn on"
# LLM_INSTRUCT_CTX_SIZE=65536
LLM_INSTRUCT_CTX_SIZE=32768
# LLM_INSTRUCT_CTX_SIZE=0
# LLM_INSTRUCT_N_PREDICT=8192
# LLM_INSTRUCT_BATCH_SIZE=512
# LLM_INSTRUCT_UBATCH_SIZE=512
# LLM_INSTRUCT_N_GPU_LAYERS=70

LLM_REASONING_MODEL_PATH=/mnt/models/models--bartowski--Qwen_Qwen3-30B-A3B-Thinking-2507-GGUF/snapshots/6a509d3e0aef5b70ffdcaa478e23de77482e6165/Qwen_Qwen3-30B-A3B-Thinking-2507-Q4_K_M.gguf

LLM_REASONING_EXTRA_PARAMS="--flash-attn on"
# LLM_REASONING_CTX_SIZE=32768
# LLM_REASONING_N_PREDICT=8192
# LLM_REASONING_BATCH_SIZE=512
# LLM_REASONING_UBATCH_SIZE=512
# LLM_REASONING_N_GPU_LAYERS=999

EMBEDDINGS_MODEL_PATH=/mnt/models/models--Qwen--Qwen3-Embedding-4B-GGUF/snapshots/f4602530db1d980e16da9d7d3a70294cf5c190be/Qwen3-Embedding-4B-Q8_0.gguf

# FOR DOWNLOAD

#LLM_INSTRUCT_MODEL_REPO=Qwen/Qwen3-30B-A3B-GGUF
#INSTRUCT_GGUF_PATTERN=Qwen3-30B-A3B-Q4_K_M.gguf
LLM_INSTRUCT_MODEL_REPO=Qwen/Qwen3-14B-GGUF
INSTRUCT_GGUF_PATTERN=Qwen3-14B-Q5_K_M.gguf

#LLM_REASONING_MODEL_REPO=mistralai/Ministral-3-14B-Reasoning-2512
#REASONING_GGUF_PATTERN=Ministral-3-14B-Reasoning-2512*.gguf
LLM_REASONING_MODEL_REPO=bartowski/Qwen_Qwen3-30B-A3B-Thinking-2507-GGUF
REASONING_GGUF_PATTERN=Qwen_Qwen3-30B-A3B-Thinking-2507-Q4_K_M.gguf

EMBEDDINGS_MODEL_REPO=Qwen/Qwen3-Embedding-4B-GGUF
EMBEDDINGS_GGUF_PATTERN=Qwen3-Embedding-4B-Q8_0.gguf



